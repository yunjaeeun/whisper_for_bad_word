import pandas as pd
import re
import pickle
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import os

# âœ… í•œêµ­ì–´ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
korean_stopwords = [
    "ì´", "ê·¸", "ì €", "ê²ƒ", "ë°", "ì˜", "ë¥¼", "ì€", "ëŠ”", "ì´ë‘", "ê³¼", "ì™€", "ìœ¼ë¡œ", "ì—ì„œ", "í•œ",
    "ë“¤", "ë‹¤", "ì", "ì¢€", "ì„", "í•˜ë‹¤", "ë“±", "ë³´ë‹¤", "ë¼ê³ ", "ì˜€ë‹¤", "í•©ë‹ˆë‹¤", "ì´ë‹¤", "í–ˆë‹¤"
]

# âœ… í…ìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ (ë¶ˆìš©ì–´ ì œê±° í¬í•¨)
def clean_text(text):
    text = text.lower()  # ì†Œë¬¸ì ë³€í™˜
    text = re.sub(r'\W', ' ', text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    text = ' '.join(word for word in text.split() if word not in korean_stopwords)  # ë¶ˆìš©ì–´ ì œê±°
    return text

# âœ… TXT íŒŒì¼ì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
data = []
with open("badwords.txt", "r", encoding="utf-8") as file:
    for line in file:
        parts = line.strip().split("|")  # | ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
        if len(parts) < 2:  # ì˜¤ë¥˜ ë°©ì§€
            continue  
        text = "|".join(parts[:-1])  # ë§ˆì§€ë§‰ ê°’(label)ì„ ì œì™¸í•œ ëª¨ë“  ë¶€ë¶„ì„ í…ìŠ¤íŠ¸ë¡œ í•©ì¹¨
        label = parts[-1]  # ë§ˆì§€ë§‰ ê°’ì´ label
        try:
            label = int(label)  # ìˆ«ìë¡œ ë³€í™˜
            data.append((text, label))
        except ValueError:
            print(f"âš ï¸ ì˜ëª»ëœ ë¼ì¸ ìŠ¤í‚µ: {line.strip()}")  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¶œë ¥

df = pd.DataFrame(data, columns=["text", "label"])

# âœ… ë°ì´í„° ë¶ˆê· í˜• í•´ê²° (ë¹„ì†ì–´ì™€ ì •ìƒ ë¬¸ì¥ ê°œìˆ˜ ê· í˜• ë§ì¶”ê¸°)
label_counts = df["label"].value_counts()
min_class = label_counts.min()  # ê°€ì¥ ì ì€ í´ë˜ìŠ¤ ê°œìˆ˜

df_balanced = pd.concat([
    df[df["label"] == 0].sample(n=min_class, random_state=42),  # ì •ìƒ ë¬¸ì¥ ëœë¤ ìƒ˜í”Œë§
    df[df["label"] == 1].sample(n=min_class, random_state=42)   # ë¹„ì†ì–´ ëœë¤ ìƒ˜í”Œë§
])

# âœ… ì „ì²˜ë¦¬ ì ìš©
df_balanced["clean_text"] = df_balanced["text"].apply(clean_text)

# âœ… TF-IDF ë²¡í„°í™” (í…ìŠ¤íŠ¸ â†’ ìˆ«ìë¡œ ë³€í™˜)
vectorizer = TfidfVectorizer(max_features=5000)

# âœ… ê¸°ì¡´ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ìˆëŠ” ê²½ìš°)
if os.path.exists("badword_model.pkl") and os.path.exists("vectorizer.pkl"):
    with open("badword_model.pkl", "rb") as f:
        model = pickle.load(f)
    with open("vectorizer.pkl", "rb") as f:
        vectorizer = pickle.load(f)

    # âœ… ê¸°ì¡´ ëª¨ë¸ì˜ ë°ì´í„°ì™€ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ê²°í•©í•˜ì—¬ í•™ìŠµ
    X = vectorizer.transform(df_balanced["clean_text"])  # ê¸°ì¡´ ë°ì´í„° ë²¡í„°í™”
    y = df_balanced["label"]

    # âœ… ëª¨ë¸ì— ìƒˆë¡œìš´ ë°ì´í„° ì¶”ê°€ í•™ìŠµ
    model.fit(X, y)
    print("ğŸ”„ ê¸°ì¡´ ëª¨ë¸ì— ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì¶”ê°€ í•™ìŠµ ì™„ë£Œ!")
else:
    # âœ… ê¸°ì¡´ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ í•™ìŠµ
    X = vectorizer.fit_transform(df_balanced["clean_text"])
    y = df_balanced["label"]
    model = RandomForestClassifier(n_estimators=200, random_state=42)
    model.fit(X, y)
    print("ğŸ†• ìƒˆ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

# âœ… ë°ì´í„° ë¶„í•  (X, yê°€ í•­ìƒ ì¡´ì¬í•˜ë„ë¡ ìˆ˜ì •ë¨!)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# âœ… ëª¨ë¸ í‰ê°€
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred) * 100
print(f"ğŸ¯ ëª¨ë¸ ì •í™•ë„: {accuracy:.2f}%")

# âœ… í•™ìŠµëœ ëª¨ë¸ ì €ì¥
with open("badword_model.pkl", "wb") as f:
    pickle.dump(model, f)

# âœ… ë²¡í„°í™” ëª¨ë¸ ì €ì¥
with open("vectorizer.pkl", "wb") as f:
    pickle.dump(vectorizer, f)

print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
